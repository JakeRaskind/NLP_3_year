{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import pandas as pd\n",
    "from fake_useragent import UserAgent\n",
    "from datetime import datetime\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "session = requests.session()\n",
    "ua = UserAgent(verify_ssl=False)\n",
    "headers = {'User-Agent': ua.random}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_reviews(url_suf, headers):\n",
    "    url = 'https://www.restoran.ru' + url_suf\n",
    "    req = session.get(url, headers=headers)\n",
    "    page = req.text\n",
    "    soup = BeautifulSoup(page, 'html.parser')\n",
    "    rev_boxes = soup.find_all('div', {\"class\": \"review-wrap\"})\n",
    "    for box in rev_boxes:\n",
    "        rate_circle = box.find('div', {'class':'review-rating'})\n",
    "        rating = rate_circle.find('span').text\n",
    "        if rating in ('1.0', '5.0'):\n",
    "            review_place = box.find('span', {'class': 'review-text-full'})\n",
    "            if review_place is None:\n",
    "                review_place = box.find('span', {'class': 'review-text-preview'})\n",
    "            if rating == '1.0':\n",
    "                bad.append(review_place.text)\n",
    "            else:\n",
    "                good.append(review_place.text)\n",
    "    next_page = soup.find('a', {'class': 'next icon-arrow-right'})\n",
    "    if next_page is not None and not next_page['href'].startswith('javascript'):\n",
    "        get_reviews(next_page['href'], headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_nth_page(page_number, headers):\n",
    "    global good, bad\n",
    "    url = 'https://www.restoran.ru/msk/catalog/restaurants/all/?page=' + str(page_number)\n",
    "    req = session.get(url, headers=headers)\n",
    "    page = req.text\n",
    "    soup = BeautifulSoup(page, 'html.parser')\n",
    "    restaurants = soup.find_all('a', {'class': 'reviews-link'})\n",
    "    for rest in restaurants:\n",
    "        get_reviews(rest['href'], headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_all(n_pages, headers):\n",
    "    for i in tqdm(range(n_pages)):\n",
    "        get_nth_page(i+1, headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "912e0f7680db4e38bf87b5decf887bd7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=10.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "good = []\n",
    "bad = []\n",
    "run_all(10, headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymorphy2 import MorphAnalyzer\n",
    "from string import punctuation\n",
    "from nltk.tokenize import word_tokenize\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_revs(morph, revs):\n",
    "    lemmas = []\n",
    "    for text in revs:\n",
    "        tokens = word_tokenize(text)\n",
    "        for word in tokens:\n",
    "            word = word.strip(punctuation).lower()\n",
    "            if word.isalpha():\n",
    "                lemmas.append(morph.parse(word)[0].normal_form)\n",
    "    count = Counter(lemmas)\n",
    "    count = count.most_common(int(len(count) * 0.9))\n",
    "    com_words = set([word[0] for word in count])\n",
    "    return com_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "morph = MorphAnalyzer()\n",
    "bad_com = parse_revs(morph, bad[:int(len(bad)*0.8)])\n",
    "good_com = parse_revs(morph, good[:int(len(good)*0.8)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_bad = bad_com - good_com\n",
    "dist_good = good_com - bad_com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def identify_review(morph, review):\n",
    "    lemmas = []\n",
    "    tokens = word_tokenize(review)\n",
    "    for word in tokens:\n",
    "        word = word.strip(punctuation).lower()\n",
    "        if word.isalpha():\n",
    "            lemmas.append(morph.parse(word)[0].normal_form)\n",
    "    words = set(lemmas)\n",
    "    goodness = len(dist_good & words)\n",
    "    badness = len(dist_bad & words)\n",
    "    return (goodness > badness)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9183965640658555\n"
     ]
    }
   ],
   "source": [
    "test_data = list(zip(bad[int(len(bad)*0.8):], [0]*int(len(bad)*0.8)))\n",
    "test_data.extend(list(zip(good[int(len(bad)*0.8):], [1]*int(len(good)*0.8))))\n",
    "y_true = [r[1] for r in test_data]\n",
    "y_pred = [identify_review(morph, r[0]) for r in test_data]\n",
    "print(accuracy_score(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Во-первых, из-за дисбаланса классов в обучающей выборке для оценки качества модели лучше использовать не accuracy, а F-score (или просто посмотреть точность и полноту).\n",
    "\n",
    "Во-вторых, можно привесить словам веса в соответствии с количеством их употреблений в хороших/плохих отзывах, и учитывать это при оценке.\n",
    "\n",
    "В-третьих, нарицательное имя или прилагательное в кавычках - признак сарказма и, соответственно, негативного отзыва, это тоже можно учесть\n",
    "\n",
    "В-четвертых (не NLP), если на сайте продавцы/владельцы заведения могут оставлять комментарии под отзывами, то с большей вероятностью комментарии (в особенности с извинениями) будут под плохими отзывами, это тоже можно проверить при парсинге (нвличие комментариев, а также слов типа \"жаль\" в них)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
